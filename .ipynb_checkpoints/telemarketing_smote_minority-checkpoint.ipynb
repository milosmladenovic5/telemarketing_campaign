{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "bank_data = pd.read_csv('bank-additional-full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handling categorical variables\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month','day_of_week', 'poutcome', 'y']\n",
    "bank_data_tran = pd.get_dummies(bank_data, columns = categorical_features, drop_first=True)\n",
    "\n",
    "bank_data_tran.drop(['duration'], axis = 1, inplace = True)\n",
    "\n",
    "#because of the high correlation coefficient between euribor3m rate and nr. of employed, the latter is going to be dropped\n",
    "bank_data_tran.drop(['nr.employed'], axis = 1, inplace = True)\n",
    "\n",
    "#apllying the same logic, emp.var.rate is going to be dropped\n",
    "bank_data_tran.drop(['emp.var.rate'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data preprocessing and splitting and scaling\n",
    "x = bank_data_tran.iloc[:,bank_data_tran.columns != 'y_yes'].values\n",
    "y = bank_data_tran.iloc[:, -1].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=12, ratio = 1.0, k_neighbors = 5)\n",
    "x_train_res, y_train_res = sm.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for printing results\n",
    "def print_results(x_input, true_output, predicted_output, classifier):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, classifier.predict_proba(x_input)[:,1])\n",
    "    area = auc(recall, precision)\n",
    "    print(\"\\nArea under precission-recall is:\", area)\n",
    "    \n",
    "    print(\"Validation set predictions: \\n\\n\" + classification_report(true_output,predicted_output))\n",
    "    print(\"\\n Confusion matrix:\\n \" , confusion_matrix(true_output, predicted_output))\n",
    "    print(\"\\n\")\n",
    "    print(\"True negatives:\", confusion_matrix(true_output, predicted_output)[0][0])\n",
    "    print(\"False positives:\", confusion_matrix(true_output, predicted_output)[0][1])\n",
    "    print(\"False negatives:\", confusion_matrix(true_output, predicted_output)[1][0])\n",
    "    print(\"True positives: \", confusion_matrix(true_output, predicted_output)[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.54447406992\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.93      0.94      5841\n",
      "          1       0.51      0.53      0.52       749\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5461  380]\n",
      " [ 355  394]]\n",
      "True negatives: 5461\n",
      "False positives: 380\n",
      "False negatives: 355\n",
      "True positives:  394\n"
     ]
    }
   ],
   "source": [
    "#Decision tree algorithm\n",
    "\n",
    "td_classifier = DecisionTreeClassifier(criterion='entropy', random_state = 0, splitter = 'best')\n",
    "td_classifier.fit(x_train_res, y_train_res)\n",
    "\n",
    "predictions_DT_val = td_classifier.predict(x_val)\n",
    "\n",
    "print_results(x_val, y_val, predictions_DT_val, td_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95      5841\n",
      "          1       0.61      0.57      0.59       749\n",
      "\n",
      "avg / total       0.91      0.91      0.91      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5562  279]\n",
      " [ 319  430]]\n",
      "\n",
      "Area under precission-recall is: 0.614624516763\n"
     ]
    }
   ],
   "source": [
    "#Boosting \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20),\n",
    "                         algorithm = \"SAMME\",\n",
    "                         n_estimators=200)\n",
    "                         \n",
    "ada.fit(x_train_res, y_train_res)\n",
    "predictions_ada = ada.predict(x_val)\n",
    "\n",
    "print_results(x_val, y_val, predictions_ada, ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.94      0.95      5841\n",
      "          1       0.59      0.64      0.61       749\n",
      "\n",
      "avg / total       0.91      0.91      0.91      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5504  337]\n",
      " [ 273  476]]\n",
      "\n",
      "Area under precission-recall is: 0.628834260863\n"
     ]
    }
   ],
   "source": [
    "#Gradient boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradientBoost = GradientBoostingClassifier(n_estimators=100, random_state=1)\n",
    "gradientBoost.fit(x_train_res, y_train_res)\n",
    "\n",
    "gradient_predictions = gradientBoost.predict(x_val)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, gradient_predictions, gradientBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.603609082238\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95      5841\n",
      "          1       0.58      0.58      0.58       749\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5524  317]\n",
      " [ 314  435]]\n",
      "True negatives: 5524\n",
      "False positives: 317\n",
      "False negatives: 314\n",
      "True positives:  435\n"
     ]
    }
   ],
   "source": [
    "#Bagging with decission trees\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagg = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=20), n_estimators=100, random_state=7)\n",
    "bagg.fit(x_train_res, y_train_res)\n",
    "\n",
    "predictions_bag = bagg.predict(x_val)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, predictions_bag, bagg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.649656501921\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.96      0.95      5841\n",
      "          1       0.62      0.50      0.56       749\n",
      "\n",
      "avg / total       0.90      0.91      0.90      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5613  228]\n",
      " [ 372  377]]\n",
      "True negatives: 5613\n",
      "False positives: 228\n",
      "False negatives: 372\n",
      "True positives:  377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n##Computing false and true positive rates\\nfpr, tpr,_=roc_curve(y_val, predictions_RF_val, drop_intermediate=False)\\n\\nimport matplotlib.pyplot as plt\\nplt.figure()\\n##Adding the ROC\\nplt.plot(fpr, tpr, color=\\'red\\',\\n lw=2, label=\\'ROC curve\\')\\n##Random FPR and TPR\\nplt.plot([0, 1], [0, 1], color=\\'blue\\', lw=2, linestyle=\\'--\\')\\n##Title and label\\nplt.xlabel(\\'FPR\\')\\nplt.ylabel(\\'TPR\\')\\nplt.title(\\'ROC curve\\')\\nplt.show() \\n\\nprint(\"Score\", roc_auc_score(y_val, predictions_RF_val))'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Classification Algorithm\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(x_train_res, y_train_res)\n",
    "\n",
    "# Predicting the Test set results\n",
    "predictions_RF_val = classifier.predict(x_val)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#cm = confusion_matrix(y_val, predictions_RF)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, predictions_RF_val, classifier)\n",
    "\n",
    "#predictions_RF_test = classifier.predict(x_test)\n",
    "#print(\"Test predictions:\\n\\n \" + classification_report(y_test, predictions_RF_test))\n",
    "\n",
    "\"\"\"\n",
    "##Computing false and true positive rates\n",
    "fpr, tpr,_=roc_curve(y_val, predictions_RF_val, drop_intermediate=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "##Adding the ROC\n",
    "plt.plot(fpr, tpr, color='red',\n",
    " lw=2, label='ROC curve')\n",
    "##Random FPR and TPR\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "##Title and label\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show() \n",
    "\n",
    "print(\"Score\", roc_auc_score(y_val, predictions_RF_val))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "x_train_res = sc.fit_transform(x_train_res)\n",
    "x_test = sc.transform(x_test)\n",
    "x_val = sc.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.562911681776\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.86      0.91      5841\n",
      "          1       0.44      0.88      0.59       749\n",
      "\n",
      "avg / total       0.92      0.86      0.88      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5002  839]\n",
      " [  91  658]]\n",
      "True negatives: 5002\n",
      "False positives: 839\n",
      "False negatives: 91\n",
      "True positives:  658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"##Computing false and true positive rates\\nfpr, tpr,_=roc_curve(predictions_LR,y_val,drop_intermediate=False)\\n\\nimport matplotlib.pyplot as plt\\nplt.figure()\\n##Adding the ROC\\nplt.plot(fpr, tpr, color='red',\\n lw=2, label='ROC curve')\\n##Random FPR and TPR\\nplt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\\n##Title and label\\nplt.xlabel('FPR')\\nplt.ylabel('TPR')\\nplt.title('ROC curve')\\nplt.show() \""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression Algorithm\n",
    "\n",
    "logdown = LogisticRegression()\n",
    "logdown.fit(x_train_res, y_train_res)\n",
    "predictions_LR = logdown.predict(x_val)\n",
    "\n",
    "print_results(x_val, y_val, predictions_LR, logdown)\n",
    "\n",
    "\"\"\"##Computing false and true positive rates\n",
    "fpr, tpr,_=roc_curve(predictions_LR,y_val,drop_intermediate=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "##Adding the ROC\n",
    "plt.plot(fpr, tpr, color='red',\n",
    " lw=2, label='ROC curve')\n",
    "##Random FPR and TPR\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "##Title and label\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y_pred_prob = logdown.predict_proba(x_val)[:, 1]\n",
    "\n",
    "##plt.rcParams['font.size'] = 14\n",
    "#plt.hist(y_pred_prob, bins = 8)\n",
    "#plt.xlim(0,1)\n",
    "#plt.title(\"Historgram of predicted probabilities\")\n",
    "#plt.xlabel(\"Predicted probability of telemarketing\")\n",
    "#plt.ylabel(\"Frequency\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Since we can see highest number of instances have class probability around 0.25, we will set that as a limit, maybe 0.3\n",
    "y_pred_prob = y_pred_prob.reshape(1,-1)\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred_class = binarize(y_pred_prob, 0.1)[0]\n",
    "\n",
    "print (confusion_matrix(y_val, y_pred_class))\n",
    "print(classification_report(y_val,y_pred_class))\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_val, y_pred_class)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "##Computing false and true positive rates\n",
    "fpr, tpr,_=roc_curve(y_val, y_pred_class,drop_intermediate=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "##Adding the ROC\n",
    "plt.plot(fpr, tpr, color='red',\n",
    " lw=2, label='ROC curve')\n",
    "##Random FPR and TPR\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "##Title and label\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM algorithm\n",
    "\n",
    "#svm_classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "#svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "#predictions_SVC_val = svm_classifier.predict(x_val)\n",
    "#print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,predictions_SVC_val))\n",
    "\n",
    "#predictions_SVC_test = svm_classifier.predict(x_test)\n",
    "#print(\"Test set predictions:\\n\\n\" + classification_report(y_test, predictions_SVC_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1a41fc8d73a3>\", line 14, in <module>\n",
      "    knn_classifier.fit(x_train, y_train)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\", line 790, in fit\n",
      "    return self._fit(X)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\", line 248, in _fit\n",
      "    **self.effective_metric_params_)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\inspect.py\", line 669, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "#KNN Algorithm\n",
    "\n",
    "#knn_classifier = KNeighborsClassifier(n_neighbors=25, metric = 'minkowski', p = 2)\n",
    "#knn_classifier.fit(x_train, y_train)\n",
    "\n",
    "#predictions_KNN_val = knn_classifier.predict(x_val)\n",
    "#print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,predictions_KNN_val))\n",
    "\n",
    "error_rate = []\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,10):    \n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=i, metric = 'minkowski', p = 2)\n",
    "    knn_classifier.fit(x_train, y_train)\n",
    "    pred_i = knn_classifier.predict(x_val)\n",
    "    error_rate.append(np.mean(pred_i != y_val))\n",
    "#predictions_KNN_test = knn_classifier.predict(x_test)\n",
    "#print(\"Test set predictions:\\n\\n\" + classification_report(y_test, predictions_KNN_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-85f724bcbbcb>\", line 3, in <module>\n",
      "    markerfacecolor='red', markersize=10)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\", line 3154, in plot\n",
      "    ax = gca()\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\", line 936, in gca\n",
      "    return gcf().gca(**kwargs)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 1359, in gca\n",
      "    return self.add_subplot(1, 1, 1, **kwargs)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 1005, in add_subplot\n",
      "    a = subplot_class_factory(projection_class)(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_subplots.py\", line 73, in __init__\n",
      "    self._axes_class.__init__(self, fig, self.figbox, **kwargs)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 503, in __init__\n",
      "    self._init_axis()\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 564, in _init_axis\n",
      "    self.yaxis = maxis.YAxis(self)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 660, in __init__\n",
      "    self.cla()\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 744, in cla\n",
      "    self.reset_ticks()\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 759, in reset_ticks\n",
      "    self.minorTicks.extend([self._get_tick(major=False)])\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 2002, in _get_tick\n",
      "    return YTick(self.axes, 0, '', major=major, **tick_kw)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 151, in __init__\n",
      "    self.tick2line = self._get_tick2line()\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 554, in _get_tick2line\n",
      "    zorder=self._zorder)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\lines.py\", line 354, in __init__\n",
      "    self.set_marker(marker)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\lines.py\", line 1110, in set_marker\n",
      "    self._marker.set_marker(marker)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\markers.py\", line 255, in set_marker\n",
      "    self._recache()\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\markers.py\", line 193, in _recache\n",
      "    self._marker_function()\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\markers.py\", line 685, in _set_tickleft\n",
      "    self._transform = Affine2D().scale(-1.0, 1.0)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 1966, in scale\n",
      "    self._mtx = np.dot(scale_mtx, self._mtx)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\inspect.py\", line 709, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\py\\_apipkg.py\", line 171, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\py\\_apipkg.py\", line 155, in getmod\n",
      "    x = importobj(modpath, None)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\py\\_apipkg.py\", line 48, in importobj\n",
      "    module = __import__(modpath, None, None, ['__doc__'])\n",
      "  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 673, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 661, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 750, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 818, in get_data\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23fc2c6db70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(range(1,50),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c1cbd45a9038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mknn_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'minkowski'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mknn_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation set predictions: \\n\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    246\u001b[0m             self._tree = KDTree(X, self.leaf_size,\n\u001b[1;32m    247\u001b[0m                                 \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                                 **self.effective_metric_params_)\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'brute'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors=28, metric = 'minkowski', p = 2)\n",
    "knn_classifier.fit(x_train_res, y_train_res)\n",
    "pred_i = knn_classifier.predict(x_val)\n",
    "\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, pred_i, knn_classifier)\n",
    "\n",
    "\"\"\"##Computing false and true positive rates\n",
    "fpr, tpr,_=roc_curve(y_val, pred_i, drop_intermediate=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "##Adding the ROC\n",
    "plt.plot(fpr, tpr, color='red',\n",
    " lw=2, label='ROC curve')\n",
    "##Random FPR and TPR\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "##Title and label\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\n",
      "Area under precission-recall is: 0.481129774891\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.90      0.92      5841\n",
      "          1       0.42      0.54      0.47       749\n",
      "\n",
      "avg / total       0.88      0.86      0.87      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5284  557]\n",
      " [ 345  404]]\n",
      "\n",
      "\n",
      "True negatives: 5284\n",
      "False positives: 557\n",
      "False negatives: 345\n",
      "True positives:  404\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# load the iris datasets\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "model.fit(x_train_res, y_train_res)\n",
    "# make predictions\n",
    "predicted = model.predict(x_val)\n",
    "# summarize the fit of the model\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, predicted, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8f0c652db780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n\u001b[0m\u001b[1;32m      5\u001b[0m                          \u001b[0malgorithm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"SAMME\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                          n_estimators=200)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "#Boosting \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm = \"SAMME\",\n",
    "                         n_estimators=200)\n",
    "                         \n",
    "ada.fit(x_train_res, y_train_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
