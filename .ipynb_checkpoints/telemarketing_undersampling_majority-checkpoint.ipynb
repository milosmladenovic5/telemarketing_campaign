{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, average_precision_score, precision_recall_curve, auc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "bank_data = pd.read_csv('bank-additional-full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handling categorical variables\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month','day_of_week', 'poutcome', 'y']\n",
    "bank_data_tran = pd.get_dummies(bank_data, columns = categorical_features, drop_first=True)\n",
    "\n",
    "bank_data_tran.drop(['duration'], axis = 1, inplace = True)\n",
    "\n",
    "#because of the high correlation coefficient between euribor3m rate and nr. of employed, the latter is going to be dropped\n",
    "bank_data_tran.drop(['nr.employed'], axis = 1, inplace = True)\n",
    "\n",
    "#apllying the same logic, emp.var.rate is going to be dropped\n",
    "bank_data_tran.drop(['emp.var.rate'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for printing results\n",
    "def print_results(x_input, true_output, predicted_output, classifier):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, classifier.predict_proba(x_input)[:,1])\n",
    "    area = auc(recall, precision)\n",
    "    print(\"\\nArea under precission-recall is:\", area)\n",
    "    \n",
    "    print(\"Validation set predictions: \\n\\n\" + classification_report(true_output,predicted_output))\n",
    "    print(\"\\n Confusion matrix:\\n \" , confusion_matrix(true_output, predicted_output))\n",
    "    print(\"\\n\")\n",
    "    print(\"True negatives:\", confusion_matrix(true_output, predicted_output)[0][0])\n",
    "    print(\"False positives:\", confusion_matrix(true_output, predicted_output)[0][1])\n",
    "    print(\"False negatives:\", confusion_matrix(true_output, predicted_output)[1][0])\n",
    "    print(\"True positives: \", confusion_matrix(true_output, predicted_output)[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Data preprocessing and splitting and scaling\n",
    "msk = np.random.rand(len(bank_data_tran)) < 0.8\n",
    "\n",
    "train = bank_data_tran[msk]\n",
    "test = bank_data_tran[~msk]\n",
    "\n",
    "msk2 = np.random.rand(len(train)) < 0.8\n",
    "\n",
    "train2 = train[msk2]\n",
    "val = train[~msk2]\n",
    "\n",
    "\n",
    "x = bank_data_tran.iloc[:,bank_data_tran.columns != 'y_yes'].values\n",
    "y = bank_data_tran.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Downsampled\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = train2[train2.y_yes ==0]\n",
    "df_minority = train2[train2.y_yes ==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=5000,     # to match minority class\n",
    "                                 random_state=123) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5000\n",
       "1    2946\n",
       "Name: y_yes, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsampled.y_yes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Data preprocessing and splitting \n",
    "x_down = df_downsampled.iloc[:,df_downsampled.columns != 'y_yes'].values\n",
    "y_down = df_downsampled.iloc[:, -1].values\n",
    "\n",
    "x_train = x_down\n",
    "y_train = y_down\n",
    "\n",
    "x_val = val.iloc[:, val.columns != 'y_yes'].values\n",
    "y_val = val.iloc[:, -1].values\n",
    "\n",
    "x_test = test.iloc[:, test.columns!='y_yes'].values\n",
    "y_test = test.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.4262191568742837\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.75      0.83      5805\n",
      "          1       0.23      0.57      0.33       784\n",
      "\n",
      "avg / total       0.85      0.73      0.77      6589\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[4356 1449]\n",
      " [ 339  445]]\n",
      "\n",
      "\n",
      "True negatives: 4356\n",
      "False positives: 1449\n",
      "False negatives: 339\n",
      "True positives:  445\n"
     ]
    }
   ],
   "source": [
    "#Decision tree algorithm\n",
    "td_classifier = DecisionTreeClassifier(criterion='entropy', random_state = 0)\n",
    "td_classifier.fit(x_train, y_train)\n",
    "\n",
    "predictions_DT_val = td_classifier.predict(x_val)\n",
    "\n",
    "#Results \n",
    "print_results(x_val, y_val, predictions_DT_val, td_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.39913235270112163\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.84      0.88      5805\n",
      "          1       0.32      0.57      0.41       784\n",
      "\n",
      "avg / total       0.86      0.80      0.83      6589\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[4851  954]\n",
      " [ 338  446]]\n",
      "\n",
      "\n",
      "True negatives: 4851\n",
      "False positives: 954\n",
      "False negatives: 338\n",
      "True positives:  446\n"
     ]
    }
   ],
   "source": [
    "#Boosting - AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20),\n",
    "                         algorithm = \"SAMME\",\n",
    "                         n_estimators=200)\n",
    "                         \n",
    "ada.fit(x_train, y_train)\n",
    "predictions_ada = ada.predict(x_val)\n",
    "\n",
    "\n",
    "\n",
    "print_results(x_val, y_val, predictions_ada, ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.4671765064134424\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.90      0.92      5805\n",
      "          1       0.44      0.58      0.50       784\n",
      "\n",
      "avg / total       0.88      0.86      0.87      6589\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5234  571]\n",
      " [ 328  456]]\n",
      "\n",
      "\n",
      "True negatives: 5234\n",
      "False positives: 571\n",
      "False negatives: 328\n",
      "True positives:  456\n"
     ]
    }
   ],
   "source": [
    "#Gradient boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradientBoost = GradientBoostingClassifier(n_estimators=100, random_state=1)\n",
    "gradientBoost.fit(x_train, y_train)\n",
    "\n",
    "gradient_predictions = gradientBoost.predict(x_val)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, gradient_predictions, gradientBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5a67934e6303>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbagg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbagg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpredictions_bag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbagg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train_res' is not defined"
     ]
    }
   ],
   "source": [
    "#Bagging with decission trees\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagg = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=20), n_estimators=100, random_state=7)\n",
    "bagg.fit(x_train_res, y_train_res)\n",
    "\n",
    "predictions_bag = bagg.predict(x_val)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, predictions_bag, bagg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.45565005571591666\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.89      0.91      5813\n",
      "          1       0.41      0.57      0.48       814\n",
      "\n",
      "avg / total       0.87      0.85      0.86      6627\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5148  665]\n",
      " [ 346  468]]\n",
      "\n",
      "\n",
      "True negatives: 5148\n",
      "False positives: 665\n",
      "False negatives: 346\n",
      "True positives:  468\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classification Algorithm\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "predictions_RF_val = classifier.predict(x_val)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#cm = confusion_matrix(y_val, predictions_RF)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, predictions_RF_val, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Scaling, because it isn't needed for Random Forest and Decision treefa\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "x_val = sc.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.45719880242425104\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.83      0.89      5805\n",
      "          1       0.34      0.63      0.44       784\n",
      "\n",
      "avg / total       0.87      0.81      0.83      6589\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[4842  963]\n",
      " [ 293  491]]\n",
      "\n",
      "\n",
      "True negatives: 4842\n",
      "False positives: 963\n",
      "False negatives: 293\n",
      "True positives:  491\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Algorithm\n",
    "logdown = LogisticRegression(class_weight = 'balanced')\n",
    "logdown.fit(x_train, y_train)\n",
    "predictions_LR = logdown.predict(x_val)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, predictions_LR, logdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.4334487567606329\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.92      0.93      5805\n",
      "          1       0.47      0.54      0.50       784\n",
      "\n",
      "avg / total       0.88      0.87      0.88      6589\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5324  481]\n",
      " [ 362  422]]\n",
      "\n",
      "\n",
      "True negatives: 5324\n",
      "False positives: 481\n",
      "False negatives: 362\n",
      "True positives:  422\n"
     ]
    }
   ],
   "source": [
    "#SVM algorithm\n",
    "\n",
    "svm_classifier = SVC(kernel = 'linear', random_state = 0, probability = True)\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "predictions_SVC_val = svm_classifier.predict(x_val)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, predictions_SVC_val, svm_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.3928402495515153\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.91      0.91      5813\n",
      "          1       0.40      0.43      0.41       814\n",
      "\n",
      "avg / total       0.86      0.85      0.85      6627\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5281  532]\n",
      " [ 462  352]]\n",
      "\n",
      "\n",
      "True negatives: 5281\n",
      "False positives: 532\n",
      "False negatives: 462\n",
      "True positives:  352\n"
     ]
    }
   ],
   "source": [
    "#KNN Algorithm\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=4, metric = 'minkowski', p = 2)\n",
    "knn_classifier.fit(x_train, y_train)\n",
    "\n",
    "predictions_KNN_val = knn_classifier.predict(x_val)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, predictions_KNN_val, knn_classifier)\n",
    "\n",
    "#predictions_KNN_test = knn_classifier.predict(x_test)\n",
    "#print(\"Test set predictions:\\n\\n\" + classification_report(y_test, predictions_KNN_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian_classifier = GaussianNB()\n",
    "gaussian_classifier.fit(x_train, y_train)\n",
    "#print(gaussian_classifier)\n",
    "# make predictions\n",
    "predicted = gaussian_classifier.predict(x_val)\n",
    "# summarize the fit of the model\n",
    "\n",
    "print_results(x_val, y_val, predicted, gaussian_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
