{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, average_precision_score, precision_recall_curve, auc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "bank_data = pd.read_csv('bank-additional-full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Handling categorical variables\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month','day_of_week', 'poutcome', 'y']\n",
    "bank_data_tran = pd.get_dummies(bank_data, columns = categorical_features, drop_first=True)\n",
    "\n",
    "bank_data_tran.drop(['duration'], axis = 1, inplace = True)\n",
    "\n",
    "#because of the high correlation coefficient between euribor3m rate and nr. of employed, the latter is going to be dropped\n",
    "bank_data_tran.drop(['nr.employed'], axis = 1, inplace = True)\n",
    "\n",
    "#apllying the same logic, emp.var.rate is going to be dropped\n",
    "bank_data_tran.drop(['emp.var.rate'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data preprocessing and splitting and scaling\n",
    "x = bank_data_tran.iloc[:,bank_data_tran.columns != 'y_yes'].values\n",
    "y = bank_data_tran.iloc[:, -1].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for printing results\n",
    "def print_results(x_input, true_output, predicted_output, classifier):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, classifier.predict_proba(x_input)[:,1])\n",
    "    area = auc(recall, precision)\n",
    "    print(\"\\nArea under precission-recall is:\", area)\n",
    "    \n",
    "    print(\"Validation set predictions: \\n\\n\" + classification_report(true_output,predicted_output))\n",
    "    print(\"\\n Confusion matrix:\\n \" , confusion_matrix(true_output, predicted_output))\n",
    "    print(\"\\n\")\n",
    "    print(\"True negatives:\", confusion_matrix(true_output, predicted_output)[0][0])\n",
    "    print(\"False positives:\", confusion_matrix(true_output, predicted_output)[0][1])\n",
    "    print(\"False negatives:\", confusion_matrix(true_output, predicted_output)[1][0])\n",
    "    print(\"True positives: \", confusion_matrix(true_output, predicted_output)[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.35237034355014546\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.91      0.91      5841\n",
      "          1       0.30      0.32      0.31       749\n",
      "\n",
      "avg / total       0.84      0.84      0.84      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5287  554]\n",
      " [ 509  240]]\n",
      "\n",
      "\n",
      "True negatives: 5287\n",
      "False positives: 554\n",
      "False negatives: 509\n",
      "True positives:  240\n"
     ]
    }
   ],
   "source": [
    "#Decision tree algorithm\n",
    "\n",
    "td_classifier = DecisionTreeClassifier(criterion='entropy', random_state = 0, splitter = 'best')\n",
    "td_classifier.fit(x_train, y_train)\n",
    "\n",
    "predictions_DT_val = td_classifier.predict(x_val)\n",
    "\n",
    "# Results\n",
    "print_results(x_val, y_val, predictions_DT_val, td_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.3537013618945843\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.96      0.94      5841\n",
      "          1       0.51      0.31      0.39       749\n",
      "\n",
      "avg / total       0.87      0.89      0.88      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5611  230]\n",
      " [ 514  235]]\n",
      "\n",
      "\n",
      "True negatives: 5611\n",
      "False positives: 230\n",
      "False negatives: 514\n",
      "True positives:  235\n"
     ]
    }
   ],
   "source": [
    "#Boosting - AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20),\n",
    "                         algorithm = \"SAMME\",\n",
    "                         n_estimators=200)\n",
    "                         \n",
    "ada.fit(x_train, y_train)\n",
    "predictions_ada = ada.predict(x_val)\n",
    "\n",
    "\n",
    "print_results(x_val, y_val, predictions_ada, ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.4830523120799327\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.95      5841\n",
      "          1       0.66      0.24      0.35       749\n",
      "\n",
      "avg / total       0.88      0.90      0.88      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5749   92]\n",
      " [ 571  178]]\n",
      "\n",
      "\n",
      "True negatives: 5749\n",
      "False positives: 92\n",
      "False negatives: 571\n",
      "True positives:  178\n"
     ]
    }
   ],
   "source": [
    "#Gradient boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradientBoost = GradientBoostingClassifier(n_estimators=100, random_state=1)\n",
    "gradientBoost.fit(x_train, y_train)\n",
    "\n",
    "gradient_predictions = gradientBoost.predict(x_val)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, gradient_predictions, gradientBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.44522174574666057\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94      5841\n",
      "          1       0.56      0.31      0.40       749\n",
      "\n",
      "avg / total       0.88      0.89      0.88      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5656  185]\n",
      " [ 517  232]]\n",
      "\n",
      "\n",
      "True negatives: 5656\n",
      "False positives: 185\n",
      "False negatives: 517\n",
      "True positives:  232\n"
     ]
    }
   ],
   "source": [
    "#Bagging with decission trees\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagg = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=20), n_estimators=100, random_state=7)\n",
    "bagg.fit(x_train, y_train)\n",
    "\n",
    "predictions_bag = bagg.predict(x_val)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, predictions_bag, bagg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.44236646251681155\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94      5841\n",
      "          1       0.56      0.30      0.39       749\n",
      "\n",
      "avg / total       0.87      0.89      0.88      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5670  171]\n",
      " [ 528  221]]\n",
      "\n",
      "\n",
      "True negatives: 5670\n",
      "False positives: 171\n",
      "False negatives: 528\n",
      "True positives:  221\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classification Algorithm\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "predictions_RF_val = classifier.predict(x_val)\n",
    "\n",
    "#Print results\n",
    "print_results(x_val, y_val, predictions_RF_val, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "x_train_res = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "x_val = sc.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.2924832209805112\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.56      0.70      5841\n",
      "          1       0.17      0.72      0.28       749\n",
      "\n",
      "avg / total       0.85      0.58      0.65      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[3278 2563]\n",
      " [ 213  536]]\n",
      "\n",
      "\n",
      "True negatives: 3278\n",
      "False positives: 2563\n",
      "False negatives: 213\n",
      "True positives:  536\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Algorithm\n",
    "\n",
    "logdown = LogisticRegression()\n",
    "logdown.fit(x_train, y_train)\n",
    "predictions_LR = logdown.predict(x_val)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, predictions_LR, logdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.4361633482642426\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.11      0.19      5841\n",
      "          1       0.10      0.75      0.17       749\n",
      "\n",
      "avg / total       0.70      0.18      0.19      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[ 647 5194]\n",
      " [ 190  559]]\n",
      "\n",
      "\n",
      "True negatives: 647\n",
      "False positives: 5194\n",
      "False negatives: 190\n",
      "True positives:  559\n"
     ]
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors=2, metric = 'minkowski', p = 2, leaf_size = 15)\n",
    "knn_classifier.fit(x_train, y_train)\n",
    "pred_i = knn_classifier.predict(x_val)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, pred_i, knn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      5841\n",
      "          1       0.11      1.00      0.20       749\n",
      "\n",
      "avg / total       0.01      0.11      0.02      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[   0 5841]\n",
      " [   0  749]]\n",
      "True negatives: 0\n",
      "False positives: 5841\n",
      "False negatives: 0\n",
      "True positives:  749\n"
     ]
    }
   ],
   "source": [
    "#SVM algorithm\n",
    "\n",
    "svm_classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "predictions_SVC_val = svm_classifier.predict(x_val)\n",
    "\n",
    "#print_results(x_val, y_val, predictions_SVC_val, svm_classifier)\n",
    "print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,predictions_SVC_val))\n",
    "print(\"\\n Confusion matrix:\\n \" , confusion_matrix(y_val, predictions_SVC_val))\n",
    "print(\"True negatives:\", confusion_matrix(y_val, predictions_SVC_val)[0][0])\n",
    "print(\"False positives:\", confusion_matrix(y_val, predictions_SVC_val)[0][1])\n",
    "print(\"False negatives:\", confusion_matrix(y_val, predictions_SVC_val)[1][0])\n",
    "print(\"True positives: \", confusion_matrix(y_val, predictions_SVC_val)[1][1])\n",
    "\n",
    "#predictions_SVC_test = svm_classifier.predict(x_test)\n",
    "#print(\"Test set predictions:\\n\\n\" + classification_report(y_test, predictions_SVC_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.5568285280728377\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      5841\n",
      "          1       0.11      1.00      0.20       749\n",
      "\n",
      "avg / total       0.01      0.11      0.02      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[   0 5841]\n",
      " [   0  749]]\n",
      "\n",
      "\n",
      "True negatives: 0\n",
      "False positives: 5841\n",
      "False negatives: 0\n",
      "True positives:  749\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian_classifier = GaussianNB()\n",
    "gaussian_classifier.fit(x_train, y_train)\n",
    "#print(gaussian_classifier)\n",
    "# make predictions\n",
    "predicted = gaussian_classifier.predict(x_val)\n",
    "# summarize the fit of the model\n",
    "\n",
    "print_results(x_val, y_val, predicted, gaussian_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
