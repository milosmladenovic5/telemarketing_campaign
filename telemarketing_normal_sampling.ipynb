{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "bank_data = pd.read_csv('bank-additional-full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Handling categorical variables\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month','day_of_week', 'poutcome', 'y']\n",
    "bank_data_tran = pd.get_dummies(bank_data, columns = categorical_features, drop_first=True)\n",
    "\n",
    "#because of the high correlation coefficient between euribor3m rate and nr. of employed, the latter is going to be dropped\n",
    "bank_data_tran.drop(['nr.employed'], axis = 1, inplace = True)\n",
    "\n",
    "#apllying the same logic, emp.var.rate is going to be dropped\n",
    "bank_data_tran.drop(['emp.var.rate'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data preprocessing and splitting and scaling\n",
    "x = bank_data_tran.iloc[:,bank_data_tran.columns != 'y_yes'].values\n",
    "y = bank_data_tran.iloc[:, -1].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.93      0.94      5841\n",
      "          1       0.50      0.54      0.52       749\n",
      "\n",
      "avg / total       0.89      0.89      0.89      6590\n",
      "\n",
      "[[5437  404]\n",
      " [ 343  406]] \n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5437  404]\n",
      " [ 343  406]]\n",
      "\n",
      "Area under precission-recall is: 0.547669600545\n"
     ]
    }
   ],
   "source": [
    "#Decision tree algorithm\n",
    "\n",
    "td_classifier = DecisionTreeClassifier(criterion='entropy', random_state = 0, splitter = 'best')\n",
    "td_classifier.fit(x_train, y_train)\n",
    "\n",
    "predictions_DT_val = td_classifier.predict(x_val)\n",
    "print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,predictions_DT_val))\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_val, predictions_DT_val)\n",
    "print(\"Confusion matrix looks like this: \\n\", cm)\n",
    "\n",
    "print(\"\\n Confusion matrix:\\n \" , confusion_matrix(y_val, predictions_DT_val))\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, td_classifier.predict_proba(x_val)[:,1])\n",
    "area = auc(recall, precision)\n",
    "print(\"\\nArea under precission-recall is:\", area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5646  195]\n",
      " [ 390  359]]\n",
      "Average precision-recall score: 0.37\n",
      "\n",
      "Area under precission-recall is: 0.657836388889\n",
      "\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.95      5841\n",
      "          1       0.65      0.48      0.55       749\n",
      "\n",
      "avg / total       0.90      0.91      0.91      6590\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n##Computing false and true positive rates\\nfpr, tpr,_=roc_curve(y_val, predictions_RF_val, drop_intermediate=False)\\n\\nimport matplotlib.pyplot as plt\\nplt.figure()\\n##Adding the ROC\\nplt.plot(fpr, tpr, color=\\'red\\',\\n lw=2, label=\\'ROC curve\\')\\n##Random FPR and TPR\\nplt.plot([0, 1], [0, 1], color=\\'blue\\', lw=2, linestyle=\\'--\\')\\n##Title and label\\nplt.xlabel(\\'FPR\\')\\nplt.ylabel(\\'TPR\\')\\nplt.title(\\'ROC curve\\')\\nplt.show() \\n\\nprint(\"Score\", roc_auc_score(y_val, predictions_RF_val))'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Classification Algorithm\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "predictions_RF_val = classifier.predict(x_val)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#cm = confusion_matrix(y_val, predictions_RF)\n",
    "\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_val, predictions_RF_val)\n",
    "print(\"Confusion matrix looks like this: \\n\", cm)\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_val, predictions_RF_val)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, classifier.predict_proba(x_val)[:,1])\n",
    "area = auc(recall, precision)\n",
    "print(\"\\nArea under precission-recall is:\", area)\n",
    "\n",
    "print(\"\\nValidation set predictions: \\n\\n\" + classification_report(y_val,predictions_RF_val))\n",
    "\n",
    "#predictions_RF_test = classifier.predict(x_test)\n",
    "#print(\"Test predictions:\\n\\n \" + classification_report(y_test, predictions_RF_test))\n",
    "\n",
    "\"\"\"\n",
    "##Computing false and true positive rates\n",
    "fpr, tpr,_=roc_curve(y_val, predictions_RF_val, drop_intermediate=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "##Adding the ROC\n",
    "plt.plot(fpr, tpr, color='red',\n",
    " lw=2, label='ROC curve')\n",
    "##Random FPR and TPR\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "##Title and label\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show() \n",
    "\n",
    "print(\"Score\", roc_auc_score(y_val, predictions_RF_val))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "x_train_res = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "x_val = sc.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area is 0.3039099889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.49      0.64      5841\n",
      "          1       0.16      0.77      0.27       749\n",
      "\n",
      "avg / total       0.85      0.52      0.60      6590\n",
      "\n",
      "\n",
      "Area under precission-recall is: 0.3039099889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"##Computing false and true positive rates\\nfpr, tpr,_=roc_curve(predictions_LR,y_val,drop_intermediate=False)\\n\\nimport matplotlib.pyplot as plt\\nplt.figure()\\n##Adding the ROC\\nplt.plot(fpr, tpr, color='red',\\n lw=2, label='ROC curve')\\n##Random FPR and TPR\\nplt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\\n##Title and label\\nplt.xlabel('FPR')\\nplt.ylabel('TPR')\\nplt.title('ROC curve')\\nplt.show() \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression Algorithm\n",
    "\n",
    "logdown = LogisticRegression()\n",
    "logdown.fit(x_train, y_train)\n",
    "predictions_LR = logdown.predict(x_val)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, logdown.predict_proba(x_val)[:,1])\n",
    "area = auc(recall, precision)\n",
    "print(\"Area is\", area)\n",
    "\n",
    "print(classification_report(y_val,predictions_LR))\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, logdown.predict_proba(x_val)[:,1])\n",
    "area = auc(recall, precision)\n",
    "print(\"\\nArea under precission-recall is:\", area)\n",
    "\n",
    "\"\"\"##Computing false and true positive rates\n",
    "fpr, tpr,_=roc_curve(predictions_LR,y_val,drop_intermediate=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "##Adding the ROC\n",
    "plt.plot(fpr, tpr, color='red',\n",
    " lw=2, label='ROC curve')\n",
    "##Random FPR and TPR\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "##Title and label\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      1.00      0.94      5841\n",
      "          1       0.00      0.00      0.00       749\n",
      "\n",
      "avg / total       0.79      0.89      0.83      6590\n",
      "\n",
      "\n",
      "Area under precission-recall is: 0.292691997511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"##Computing false and true positive rates\\nfpr, tpr,_=roc_curve(y_val, pred_i, drop_intermediate=False)\\n\\nimport matplotlib.pyplot as plt\\nplt.figure()\\n##Adding the ROC\\nplt.plot(fpr, tpr, color='red',\\n lw=2, label='ROC curve')\\n##Random FPR and TPR\\nplt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\\n##Title and label\\nplt.xlabel('FPR')\\nplt.ylabel('TPR')\\nplt.title('ROC curve')\\nplt.show() \""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors=28, metric = 'minkowski', p = 2)\n",
    "knn_classifier.fit(x_train, y_train)\n",
    "pred_i = knn_classifier.predict(x_val)\n",
    "\n",
    "print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,pred_i))\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, knn_classifier.predict_proba(x_val)[:,1])\n",
    "area = auc(recall, precision)\n",
    "print(\"\\nArea under precission-recall is:\", area)\n",
    "\n",
    "\"\"\"##Computing false and true positive rates\n",
    "fpr, tpr,_=roc_curve(y_val, pred_i, drop_intermediate=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "##Adding the ROC\n",
    "plt.plot(fpr, tpr, color='red',\n",
    " lw=2, label='ROC curve')\n",
    "##Random FPR and TPR\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "##Title and label\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      5841\n",
      "          1       0.11      1.00      0.20       749\n",
      "\n",
      "avg / total       0.01      0.11      0.02      6590\n",
      "\n",
      "[[   0 5841]\n",
      " [   0  749]]\n",
      "\n",
      "Area under precission-recall is: 0.556828528073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# load the iris datasets\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions\n",
    "predicted = model.predict(x_val)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_val, predicted))\n",
    "print(metrics.confusion_matrix(y_val, predicted))\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, model.predict_proba(x_val)[:,1])\n",
    "area = auc(recall, precision)\n",
    "print(\"\\nArea under precission-recall is:\", area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
