{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "bank_data = pd.read_csv('bank-additional-full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handling categorical variables\n",
    "\n",
    "job = pd.get_dummies(bank_data['job'], drop_first = True)\n",
    "marital = pd.get_dummies(bank_data['marital'], drop_first = True)\n",
    "education = pd.get_dummies(bank_data['education'], drop_first = True)\n",
    "default = pd.get_dummies(bank_data['default'], drop_first = True)\n",
    "housing = pd.get_dummies(bank_data['housing'], drop_first = True)\n",
    "loan =  pd.get_dummies(bank_data['loan'], drop_first = True)\n",
    "contact = pd.get_dummies(bank_data['contact'], drop_first = True)\n",
    "month = pd.get_dummies(bank_data['month'], drop_first = True)\n",
    "day_of_week = pd.get_dummies(bank_data['day_of_week'], drop_first = True)\n",
    "poutcome = pd.get_dummies(bank_data['poutcome'], drop_first = True)\n",
    "\n",
    "#reduced set of features that is going to be concatenated to existing ones\n",
    "bank_data_red = pd.concat([job,marital,education,default,housing,loan,contact,month,day_of_week,poutcome], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Transformed bank_data set\n",
    "bank_data_tran = bank_data_red.join(bank_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bank_data_tran.drop(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome'], axis = 1, inplace = True)\n",
    "bank_data_tran.drop(['duration'], axis = 1, inplace = True)\n",
    "\n",
    "#because of the high correlation coefficient between euribor3m rate and nr. of employed, the latter is going to be dropped\n",
    "#bank_data_tran.drop(['nr.employed'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Data preprocessing and splitting and scaling\n",
    "msk = np.random.rand(len(bank_data_tran)) < 0.8\n",
    "\n",
    "train = bank_data_tran[msk]\n",
    "test = bank_data_tran[~msk]\n",
    "\n",
    "msk2 = np.random.rand(len(train)) < 0.8\n",
    "\n",
    "train2 = train[msk2]\n",
    "val = train[~msk2]\n",
    "\n",
    "\n",
    "x = bank_data_tran.iloc[:,bank_data_tran.columns != 'y'].values\n",
    "y = bank_data_tran.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Downsampled\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = train2[train2.y=='no']\n",
    "df_minority = train2[train2.y=='yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=5000,     # to match minority class\n",
    "                                 random_state=123) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     5000\n",
       "yes    2951\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsampled.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Data preprocessing and splitting and scaling\n",
    "x_down = df_downsampled.iloc[:,df_downsampled.columns != 'y'].values\n",
    "y_down = df_downsampled.iloc[:, -1].values\n",
    "\n",
    "x_train = x_down\n",
    "y_train = y_down\n",
    "\n",
    "x_val = val.iloc[:, val.columns != 'y'].values\n",
    "y_val = val.iloc[:, -1].values\n",
    "\n",
    "x_test = test.iloc[:, test.columns!='y'].values\n",
    "y_test = test.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "x_val = sc.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.95      0.84      0.89      5784\n",
      "        yes       0.35      0.67      0.46       745\n",
      "\n",
      "avg / total       0.88      0.82      0.84      6529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Algorithm\n",
    "logdown = LogisticRegression(class_weight = 'balanced')\n",
    "logdown.fit(x_train, y_train)\n",
    "predictions_LR = logdown.predict(x_val)\n",
    "\n",
    "print(classification_report(y_val,predictions_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.95      0.88      0.91      5784\n",
      "        yes       0.40      0.62      0.49       745\n",
      "\n",
      "avg / total       0.89      0.85      0.86      6529\n",
      "\n",
      "Test predictions:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         no       0.94      0.88      0.91      7276\n",
      "        yes       0.37      0.54      0.44       944\n",
      "\n",
      "avg / total       0.87      0.84      0.85      8220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classification Algorithm\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 40, criterion = 'gini', random_state = 0)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "predictions_RF_val = classifier.predict(x_val)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#cm = confusion_matrix(y_val, predictions_RF)\n",
    "\n",
    "print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,predictions_RF_val))\n",
    "\n",
    "predictions_RF_test = classifier.predict(x_test)\n",
    "\n",
    "print(\"Test predictions:\\n\\n \" + classification_report(y_test, predictions_RF_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.95      0.87      0.91      5784\n",
      "        yes       0.39      0.64      0.48       745\n",
      "\n",
      "avg / total       0.88      0.84      0.86      6529\n",
      "\n",
      "Test set predictions:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.94      0.86      0.90      7276\n",
      "        yes       0.36      0.59      0.45       944\n",
      "\n",
      "avg / total       0.88      0.83      0.85      8220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM algorithm\n",
    "\n",
    "svm_classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "predictions_SVC_val = svm_classifier.predict(x_val)\n",
    "print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,predictions_SVC_val))\n",
    "\n",
    "predictions_SVC_test = svm_classifier.predict(x_test)\n",
    "print(\"Test set predictions:\\n\\n\" + classification_report(y_test, predictions_SVC_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.94      0.90      0.92      5784\n",
      "        yes       0.42      0.54      0.47       745\n",
      "\n",
      "avg / total       0.88      0.86      0.87      6529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN Algorithm\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=10, metric = 'minkowski', p = 2)\n",
    "knn_classifier.fit(x_train, y_train)\n",
    "\n",
    "predictions_KNN_val = knn_classifier.predict(x_val)\n",
    "print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,predictions_KNN_val))\n",
    "\n",
    "#predictions_KNN_test = knn_classifier.predict(x_test)\n",
    "#print(\"Test set predictions:\\n\\n\" + classification_report(y_test, predictions_KNN_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.93      0.74      0.83      5784\n",
      "        yes       0.23      0.60      0.33       745\n",
      "\n",
      "avg / total       0.85      0.72      0.77      6529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision tree algorithm\n",
    "\n",
    "td_classifier = DecisionTreeClassifier(criterion='entropy', random_state = 0)\n",
    "td_classifier.fit(x_train, y_train)\n",
    "\n",
    "predictions_DT_val = td_classifier.predict(x_val)\n",
    "print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,predictions_DT_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
