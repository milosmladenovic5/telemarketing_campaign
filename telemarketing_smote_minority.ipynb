{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "bank_data = pd.read_csv('bank-additional-full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handling categorical variables\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month','day_of_week', 'poutcome', 'y']\n",
    "bank_data_tran = pd.get_dummies(bank_data, columns = categorical_features, drop_first=True)\n",
    "\n",
    "bank_data_tran.drop(['duration'], axis = 1, inplace = True)\n",
    "\n",
    "#because of the high correlation coefficient between euribor3m rate and nr. of employed, the latter is going to be dropped\n",
    "bank_data_tran.drop(['nr.employed'], axis = 1, inplace = True)\n",
    "\n",
    "#apllying the same logic, emp.var.rate is going to be dropped\n",
    "bank_data_tran.drop(['emp.var.rate'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data preprocessing and splitting and scaling\n",
    "x = bank_data_tran.iloc[:,bank_data_tran.columns != 'y_yes'].values\n",
    "y = bank_data_tran.iloc[:, -1].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=12, ratio = 1.0, k_neighbors = 5)\n",
    "x_train_res, y_train_res = sm.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for printing results\n",
    "def print_results(x_input, true_output, predicted_output, classifier):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, classifier.predict_proba(x_input)[:,1])\n",
    "    area = auc(recall, precision)\n",
    "    print(\"\\nArea under precission-recall is:\", area)\n",
    "    \n",
    "    print(\"Validation set predictions: \\n\\n\" + classification_report(true_output,predicted_output))\n",
    "    print(\"\\n Confusion matrix:\\n \" , confusion_matrix(true_output, predicted_output))\n",
    "    print(\"\\n\")\n",
    "    print(\"True negatives:\", confusion_matrix(true_output, predicted_output)[0][0])\n",
    "    print(\"False positives:\", confusion_matrix(true_output, predicted_output)[0][1])\n",
    "    print(\"False negatives:\", confusion_matrix(true_output, predicted_output)[1][0])\n",
    "    print(\"True positives: \", confusion_matrix(true_output, predicted_output)[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.360806085614\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.90      0.90      5841\n",
      "          1       0.30      0.34      0.32       749\n",
      "\n",
      "avg / total       0.84      0.83      0.84      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5233  608]\n",
      " [ 491  258]]\n",
      "\n",
      "\n",
      "True negatives: 5233\n",
      "False positives: 608\n",
      "False negatives: 491\n",
      "True positives:  258\n"
     ]
    }
   ],
   "source": [
    "#Decision tree algorithm\n",
    "\n",
    "td_classifier = DecisionTreeClassifier(criterion='entropy', random_state = 0, splitter = 'best')\n",
    "td_classifier.fit(x_train_res, y_train_res)\n",
    "\n",
    "predictions_DT_val = td_classifier.predict(x_val)\n",
    "\n",
    "print_results(x_val, y_val, predictions_DT_val, td_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.379999211899\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.96      0.94      5841\n",
      "          1       0.51      0.33      0.40       749\n",
      "\n",
      "avg / total       0.87      0.89      0.88      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5604  237]\n",
      " [ 501  248]]\n",
      "\n",
      "\n",
      "True negatives: 5604\n",
      "False positives: 237\n",
      "False negatives: 501\n",
      "True positives:  248\n"
     ]
    }
   ],
   "source": [
    "#Boosting - AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20),\n",
    "                         algorithm = \"SAMME\",\n",
    "                         n_estimators=200)\n",
    "                         \n",
    "ada.fit(x_train_res, y_train_res)\n",
    "predictions_ada = ada.predict(x_val)\n",
    "\n",
    "\n",
    "\n",
    "print_results(x_val, y_val, predictions_ada, ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.468162103388\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.94      5841\n",
      "          1       0.54      0.40      0.46       749\n",
      "\n",
      "avg / total       0.88      0.89      0.89      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5582  259]\n",
      " [ 450  299]]\n",
      "\n",
      "\n",
      "True negatives: 5582\n",
      "False positives: 259\n",
      "False negatives: 450\n",
      "True positives:  299\n"
     ]
    }
   ],
   "source": [
    "#Gradient boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradientBoost = GradientBoostingClassifier(n_estimators=100, random_state=1)\n",
    "gradientBoost.fit(x_train_res, y_train_res)\n",
    "\n",
    "gradient_predictions = gradientBoost.predict(x_val)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, gradient_predictions, gradientBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precission-recall is: 0.429860219451\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.95      0.94      5841\n",
      "          1       0.50      0.38      0.43       749\n",
      "\n",
      "avg / total       0.87      0.89      0.88      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5556  285]\n",
      " [ 468  281]]\n",
      "\n",
      "\n",
      "True negatives: 5556\n",
      "False positives: 285\n",
      "False negatives: 468\n",
      "True positives:  281\n"
     ]
    }
   ],
   "source": [
    "#Bagging with decission trees\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagg = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=20), n_estimators=100, random_state=7)\n",
    "bagg.fit(x_train_res, y_train_res)\n",
    "\n",
    "predictions_bag = bagg.predict(x_val)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, predictions_bag, bagg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.30363816e-02   5.00202929e-02   2.50349005e-02   2.17032439e-02\n",
      "   3.22342745e-02   3.96364869e-02   1.16257088e-01   2.71154462e-02\n",
      "   4.97161396e-03   3.75555643e-03   9.38227248e-03   4.29249841e-03\n",
      "   4.46755344e-03   1.24195488e-02   3.74028023e-03   2.36021210e-02\n",
      "   3.70154717e-03   1.16128856e-03   2.95552783e-02   1.70495689e-02\n",
      "   5.92463339e-04   6.74741636e-03   2.15809452e-02   2.70329211e-02\n",
      "   6.82474482e-05   1.72573857e-02   3.41165943e-02   4.77972661e-03\n",
      "   4.10433748e-02   0.00000000e+00   1.81649810e-03   6.60337212e-02\n",
      "   1.87774862e-03   3.14395658e-02   3.75212691e-02   4.45385570e-03\n",
      "   7.78116724e-04   4.78664941e-03   6.30596332e-03   3.39507529e-03\n",
      "   1.71808864e-02   4.13896218e-03   6.44286399e-03   1.84183057e-03\n",
      "   3.09913249e-02   3.01530666e-02   2.95176767e-02   2.60261832e-02\n",
      "   1.87439450e-02   2.01984799e-02]\n",
      "\n",
      "Area under precission-recall is: 0.433939719924\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.96      0.94      5841\n",
      "          1       0.53      0.32      0.40       749\n",
      "\n",
      "avg / total       0.87      0.89      0.88      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5630  211]\n",
      " [ 507  242]]\n",
      "\n",
      "\n",
      "True negatives: 5630\n",
      "False positives: 211\n",
      "False negatives: 507\n",
      "True positives:  242\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classification Algorithm\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(x_train_res, y_train_res)\n",
    "\n",
    "# Predicting the Test set results\n",
    "predictions_RF_val = classifier.predict(x_val)\n",
    "\n",
    "print(classifier.feature_importances_ )\n",
    "# Making the Confusion Matrix\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#cm = confusion_matrix(y_val, predictions_RF)\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, predictions_RF_val, classifier)\n",
    "\n",
    "#predictions_RF_test = classifier.predict(x_test)\n",
    "#print(\"Test predictions:\\n\\n \" + classification_report(y_test, predictions_RF_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "x_train_res = sc.fit_transform(x_train_res)\n",
    "x_test = sc.transform(x_test)\n",
    "x_val = sc.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [[ 0.00168964 -0.05494079 -0.00214708 -0.13766523  0.06176226  0.05381206\n",
      "  -0.41568604 -0.19495463 -0.11010587 -0.16507294 -0.16904108  0.08520344\n",
      "  -0.28733114 -0.30682795  0.26759707 -0.22627011 -0.2209257  -0.06888995\n",
      "   0.02983128  0.03872416  0.12972041  0.0136768  -0.08023718  0.01568799\n",
      "   0.00315044 -0.15112582  0.08693888 -0.04780459 -0.29960794  0.\n",
      "  -0.33955041  0.04772519 -0.33955041 -0.19169678 -0.46884826 -0.52499315\n",
      "   0.08560154  0.05249188  0.14891135  1.1000481  -0.7431984  -0.54084029\n",
      "   0.62398396 -0.15852713 -0.19365159 -0.01070711 -0.09455541  0.02339637\n",
      "   0.53454495  0.12333968]]\n",
      "\n",
      "Area under precission-recall is: 0.450717257292\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.83      0.88      5841\n",
      "          1       0.32      0.65      0.43       749\n",
      "\n",
      "avg / total       0.88      0.81      0.83      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[4829 1012]\n",
      " [ 265  484]]\n",
      "\n",
      "\n",
      "True negatives: 4829\n",
      "False positives: 1012\n",
      "False negatives: 265\n",
      "True positives:  484\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Algorithm\n",
    "\n",
    "logdown = LogisticRegression()\n",
    "logdown.fit(x_train_res, y_train_res)\n",
    "predictions_LR = logdown.predict(x_val)\n",
    "\n",
    "print(\"Coefficients: \",  logdown.coef_)\n",
    "\n",
    "print_results(x_val, y_val, predictions_LR, logdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM algorithm\n",
    "\n",
    "#svm_classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "#svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "#predictions_SVC_val = svm_classifier.predict(x_val)\n",
    "#print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,predictions_SVC_val))\n",
    "\n",
    "#predictions_SVC_test = svm_classifier.predict(x_test)\n",
    "#print(\"Test set predictions:\\n\\n\" + classification_report(y_test, predictions_SVC_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1a41fc8d73a3>\", line 14, in <module>\n",
      "    knn_classifier.fit(x_train, y_train)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\", line 790, in fit\n",
      "    return self._fit(X)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\", line 248, in _fit\n",
      "    **self.effective_metric_params_)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\inspect.py\", line 669, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "#KNN Algorithm\n",
    "\n",
    "#knn_classifier = KNeighborsClassifier(n_neighbors=25, metric = 'minkowski', p = 2)\n",
    "#knn_classifier.fit(x_train, y_train)\n",
    "\n",
    "#predictions_KNN_val = knn_classifier.predict(x_val)\n",
    "#print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,predictions_KNN_val))\n",
    "\n",
    "error_rate = []\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,10):    \n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=i, metric = 'minkowski', p = 2)\n",
    "    knn_classifier.fit(x_train, y_train)\n",
    "    pred_i = knn_classifier.predict(x_val)\n",
    "    error_rate.append(np.mean(pred_i != y_val))\n",
    "#predictions_KNN_test = knn_classifier.predict(x_test)\n",
    "#print(\"Test set predictions:\\n\\n\" + classification_report(y_test, predictions_KNN_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-85f724bcbbcb>\", line 3, in <module>\n",
      "    markerfacecolor='red', markersize=10)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\", line 3154, in plot\n",
      "    ax = gca()\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\", line 936, in gca\n",
      "    return gcf().gca(**kwargs)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 1359, in gca\n",
      "    return self.add_subplot(1, 1, 1, **kwargs)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 1005, in add_subplot\n",
      "    a = subplot_class_factory(projection_class)(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_subplots.py\", line 73, in __init__\n",
      "    self._axes_class.__init__(self, fig, self.figbox, **kwargs)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 503, in __init__\n",
      "    self._init_axis()\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 564, in _init_axis\n",
      "    self.yaxis = maxis.YAxis(self)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 660, in __init__\n",
      "    self.cla()\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 744, in cla\n",
      "    self.reset_ticks()\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 759, in reset_ticks\n",
      "    self.minorTicks.extend([self._get_tick(major=False)])\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 2002, in _get_tick\n",
      "    return YTick(self.axes, 0, '', major=major, **tick_kw)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 151, in __init__\n",
      "    self.tick2line = self._get_tick2line()\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 554, in _get_tick2line\n",
      "    zorder=self._zorder)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\lines.py\", line 354, in __init__\n",
      "    self.set_marker(marker)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\lines.py\", line 1110, in set_marker\n",
      "    self._marker.set_marker(marker)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\markers.py\", line 255, in set_marker\n",
      "    self._recache()\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\markers.py\", line 193, in _recache\n",
      "    self._marker_function()\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\markers.py\", line 685, in _set_tickleft\n",
      "    self._transform = Affine2D().scale(-1.0, 1.0)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 1966, in scale\n",
      "    self._mtx = np.dot(scale_mtx, self._mtx)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\inspect.py\", line 709, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\py\\_apipkg.py\", line 171, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\py\\_apipkg.py\", line 155, in getmod\n",
      "    x = importobj(modpath, None)\n",
      "  File \"C:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\py\\_apipkg.py\", line 48, in importobj\n",
      "    module = __import__(modpath, None, None, ['__doc__'])\n",
      "  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 673, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 661, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 750, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 818, in get_data\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23fc2c6db70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(range(1,50),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c1cbd45a9038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mknn_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'minkowski'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mknn_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation set predictions: \\n\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Milos\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    246\u001b[0m             self._tree = KDTree(X, self.leaf_size,\n\u001b[1;32m    247\u001b[0m                                 \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                                 **self.effective_metric_params_)\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'brute'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors=28, metric = 'minkowski', p = 2)\n",
    "knn_classifier.fit(x_train_res, y_train_res)\n",
    "pred_i = knn_classifier.predict(x_val)\n",
    "\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, pred_i, knn_classifier)\n",
    "\n",
    "\"\"\"##Computing false and true positive rates\n",
    "fpr, tpr,_=roc_curve(y_val, pred_i, drop_intermediate=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "##Adding the ROC\n",
    "plt.plot(fpr, tpr, color='red',\n",
    " lw=2, label='ROC curve')\n",
    "##Random FPR and TPR\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "##Title and label\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\n",
      "Area under precission-recall is: 0.481129774891\n",
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.90      0.92      5841\n",
      "          1       0.42      0.54      0.47       749\n",
      "\n",
      "avg / total       0.88      0.86      0.87      6590\n",
      "\n",
      "\n",
      " Confusion matrix:\n",
      "  [[5284  557]\n",
      " [ 345  404]]\n",
      "\n",
      "\n",
      "True negatives: 5284\n",
      "False positives: 557\n",
      "False negatives: 345\n",
      "True positives:  404\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# load the iris datasets\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "model.fit(x_train_res, y_train_res)\n",
    "# make predictions\n",
    "predicted = model.predict(x_val)\n",
    "# summarize the fit of the model\n",
    "\n",
    "#Results\n",
    "print_results(x_val, y_val, predicted, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8f0c652db780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n\u001b[0m\u001b[1;32m      5\u001b[0m                          \u001b[0malgorithm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"SAMME\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                          n_estimators=200)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "#Boosting \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm = \"SAMME\",\n",
    "                         n_estimators=200)\n",
    "                         \n",
    "ada.fit(x_train_res, y_train_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
