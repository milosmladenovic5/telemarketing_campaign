{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "bank_data = pd.read_csv('bank-additional-full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Handling categorical variables\n",
    "job = pd.get_dummies(bank_data['job'], drop_first = True)\n",
    "marital = pd.get_dummies(bank_data['marital'], drop_first = True)\n",
    "education = pd.get_dummies(bank_data['education'], drop_first = True)\n",
    "default = pd.get_dummies(bank_data['default'], drop_first = True)\n",
    "housing = pd.get_dummies(bank_data['housing'], drop_first = True)\n",
    "loan =  pd.get_dummies(bank_data['loan'], drop_first = True)\n",
    "contact = pd.get_dummies(bank_data['contact'], drop_first = True)\n",
    "month = pd.get_dummies(bank_data['month'], drop_first = True)\n",
    "day_of_week = pd.get_dummies(bank_data['day_of_week'], drop_first = True)\n",
    "poutcome = pd.get_dummies(bank_data['poutcome'], drop_first = True)\n",
    "\n",
    "#reduced set of features that is going to be concatenated to existing ones\n",
    "bank_data_red = pd.concat([job,marital,education,default,housing,loan,contact,month,day_of_week,poutcome], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bank_data_tran = bank_data_red.join(bank_data)\n",
    "bank_data_tran.drop(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome'], axis = 1, inplace = True)\n",
    "bank_data_tran.drop(['duration'], axis = 1, inplace = True)\n",
    "\n",
    "#because of the high correlation coefficient between euribor3m rate and nr. of employed, the latter is going to be dropped\n",
    "bank_data_tran.drop(['nr.employed'], axis = 1, inplace = True)\n",
    "\n",
    "#apllying the same logic, emp.var.rate is going to be dropped\n",
    "bank_data_tran.drop(['emp.var.rate'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data preprocessing and splitting and scaling\n",
    "x = bank_data_tran.iloc[:,bank_data_tran.columns != 'y'].values\n",
    "y = bank_data_tran.iloc[:, -1].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=12, ratio = 'auto')\n",
    "x_train, y_train = sm.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "x_val = sc.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.95      0.83      0.89      5841\n",
      "        yes       0.33      0.65      0.44       749\n",
      "\n",
      "avg / total       0.88      0.81      0.84      6590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Algorithm\n",
    "\n",
    "logdown = LogisticRegression()\n",
    "logdown.fit(x_train, y_train)\n",
    "predictions_LR = logdown.predict(x_val)\n",
    "\n",
    "print(classification_report(y_val,predictions_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.92      0.96      0.94      5841\n",
      "        yes       0.52      0.32      0.40       749\n",
      "\n",
      "avg / total       0.87      0.89      0.88      6590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classification Algorithm\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 50, criterion = 'gini', random_state = 0)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "predictions_RF_val = classifier.predict(x_val)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#cm = confusion_matrix(y_val, predictions_RF)\n",
    "\n",
    "print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,predictions_RF_val))\n",
    "\n",
    "#predictions_RF_test = classifier.predict(x_test)\n",
    "#print(\"Test predictions:\\n\\n \" + classification_report(y_test, predictions_RF_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVM algorithm\n",
    "\n",
    "#svm_classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "#svm_classifier.fit(x_train, y_train)\n",
    "\n",
    "#predictions_SVC_val = svm_classifier.predict(x_val)\n",
    "#print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,predictions_SVC_val))\n",
    "\n",
    "#predictions_SVC_test = svm_classifier.predict(x_test)\n",
    "#print(\"Test set predictions:\\n\\n\" + classification_report(y_test, predictions_SVC_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.94      0.78      0.85      5841\n",
      "        yes       0.26      0.61      0.37       749\n",
      "\n",
      "avg / total       0.86      0.76      0.80      6590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN Algorithm\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=25, metric = 'minkowski', p = 2)\n",
    "knn_classifier.fit(x_train, y_train)\n",
    "\n",
    "predictions_KNN_val = knn_classifier.predict(x_val)\n",
    "print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,predictions_KNN_val))\n",
    "\n",
    "#predictions_KNN_test = knn_classifier.predict(x_test)\n",
    "#print(\"Test set predictions:\\n\\n\" + classification_report(y_test, predictions_KNN_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set predictions: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.92      0.90      0.91      5841\n",
      "        yes       0.32      0.36      0.34       749\n",
      "\n",
      "avg / total       0.85      0.84      0.84      6590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision tree algorithm\n",
    "\n",
    "td_classifier = DecisionTreeClassifier(criterion='entropy', random_state = 0)\n",
    "td_classifier.fit(x_train, y_train)\n",
    "\n",
    "predictions_DT_val = td_classifier.predict(x_val)\n",
    "print(\"Validation set predictions: \\n\\n\" + classification_report(y_val,predictions_DT_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
